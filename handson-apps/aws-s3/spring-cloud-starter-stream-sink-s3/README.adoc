//tag::ref-doc[]
= Amazon S3 Sink

This sink app supports transfer files to the Amazon S3 bucket.
Files payloads (and directories recursively) are transferred to the `remote` directory (S3 bucket) to the `local` directory where the application is deployed.

Messages accepted by this sink must contain `payload` as:

- `File`, including directories for recursive upload;
- `InputStream`;
- `byte[]`

When using `--mode=lines`, you can also provide the additional option `--withMarkers=true`.
If set to `true`, the underlying `FileSplitter` will emit additional _start-of-file_ and _end-of-file_ marker messages before and after the actual data.
The payload of these 2 additional marker messages is of type `FileSplitter.FileMarker`. The option `withMarkers` defaults to `false` if not explicitly set.

== Input

=== Headers

N/A

=== Payload

* `java.io.File`
* `java.io.InputStream`
* `byte[]`
* `String`

== Output

N/A

== Options

The **$$s3$$** $$sink$$ has the following options:

//tag::configuration-properties[]
$$s3.acl$$:: $$S3 Object access control list.$$ *($$CannedAccessControlList$$, default: `$$<none>$$`, possible values: `private`,`public-read`,`public-read-write`,`authenticated-read`,`log-delivery-write`,`bucket-owner-read`,`bucket-owner-full-control`,`aws-exec-read`)*
$$s3.acl-expression$$:: $$Expression to evaluate S3 Object access control list.$$ *($$Expression$$, default: `$$<none>$$`)*
$$s3.bucket$$:: $$AWS bucket for target file(s) to store.$$ *($$String$$, default: `$$<none>$$`)*
$$s3.bucket-expression$$:: $$Expression to evaluate AWS bucket name.$$ *($$Expression$$, default: `$$<none>$$`)*
$$s3.key-expression$$:: $$Expression to evaluate S3 Object key.$$ *($$Expression$$, default: `$$<none>$$`)*
//end::configuration-properties[]

The target generated application based on the `AmazonS3SinkConfiguration` can be enhanced with the `S3MessageHandler.UploadMetadataProvider` and/or `S3ProgressListener`, which are injected into `S3MessageHandler` bean.

== Amazon AWS common options

The Amazon S3 Sink (as all other Amazon AWS applications) is based on the
https://github.com/spring-cloud/spring-cloud-aws[Spring Cloud AWS] project as a foundation, and its auto-configuration
classes are used automatically by Spring Boot.
Consult their documentation regarding required and useful auto-configuration properties.

Some of them are about AWS credentials:

- cloud.aws.credentials.accessKey
- cloud.aws.credentials.secretKey
- cloud.aws.credentials.instanceProfile
- cloud.aws.credentials.profileName
- cloud.aws.credentials.profilePath

Other are for AWS `Region` definition:

- cloud.aws.region.auto
- cloud.aws.region.static

And for AWS `Stack`:

- cloud.aws.stack.auto
- cloud.aws.stack.name

== Build

```
$ ./mvnw clean install -PgenerateApps
$ cd apps
```
You can find the corresponding binder based projects here. You can then cd into one one of the folders and build it:
```
$ ./mvnw clean package
```

=== Examples

```
java -jar s3-sink.jar --s3.bucket=/tmp/bar
```

//end::ref-doc[]
